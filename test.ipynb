{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Biniyamgd/IDP/blob/main/test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvozMDLVaGsl",
        "outputId": "55114ff4-be9c-4294-c009-348a9173863a",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dlib in /usr/local/lib/python3.10/dist-packages (19.24.4)\n",
            "Collecting face_recognition\n",
            "  Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting face-recognition-models>=0.3.0 (from face_recognition)\n",
            "  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.1/100.1 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (8.1.7)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (19.24.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from face_recognition) (1.25.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from face_recognition) (9.4.0)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566170 sha256=e2f5b784ce092e2eb77ed6cbeebb9387d548fb151c41994c084f04885d93babe\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/eb/cf/e9eced74122b679557f597bb7c8e4c739cfcac526db1fd523d\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face_recognition\n",
            "Successfully installed face-recognition-models-0.3.0 face_recognition-1.3.0\n",
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<firebase_admin.App at 0x785a78874100>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "#progress\n",
        "\n",
        "!pip install dlib\n",
        "!pip install face_recognition\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import firebase_admin\n",
        "from firebase_admin import credentials\n",
        "\n",
        "cred = credentials.Certificate(\"/content/drive/MyDrive/serviceAccountKey.json\")\n",
        "firebase_admin.initialize_app(cred,{\n",
        "    \"databaseURL\":\"https://facerecondb-default-rtdb.firebaseio.com/\",\n",
        "    \"storageBucket\":\"facerecondb.appspot.com\"\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "!mkdir unknown\n",
        "\n",
        "def take_photo(filename='./unknown/photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename"
      ],
      "metadata": {
        "id": "OaEtSKythY99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, clear_output\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "from threading import local\n",
        "import cv2\n",
        "import os\n",
        "import pickle\n",
        "import face_recognition\n",
        "import numpy as np\n",
        "import firebase_admin\n",
        "from firebase_admin import storage\n",
        "from firebase_admin import db\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "def Retake():\n",
        " try:\n",
        "   filename = take_photo()\n",
        "  #  print('Saved to {}'.format(filename))\n",
        "\n",
        "   # Show the image which was just taken.\n",
        "   # display(Image(filename))  #check\n",
        " except Exception as err:\n",
        "   # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "   # grant the page permission to access it.\n",
        "   print(str(err))\n",
        "\n",
        "\n",
        "\n",
        " filepath='./drive/MyDrive/students'\n",
        " folder=os.listdir(filepath)\n",
        " modelist=[]\n",
        " studentId=[]\n",
        "\n",
        "\n",
        " for Path in folder:\n",
        "  # Check if the item is a file and a supported image format before adding to modelist\n",
        "  if os.path.isfile(os.path.join(filepath, Path)) and Path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "    modelist.append(cv2.imread(os.path.join(filepath,Path)))\n",
        "    studentId.append(os.path.splitext(Path)[0])\n",
        "    imgfile=os.path.join(filepath,Path)\n",
        "    # Get the relative path to avoid including parent directories\n",
        "    relative_path = os.path.relpath(imgfile, filepath)\n",
        "    bucket=storage.bucket()\n",
        "    blob = bucket.blob(relative_path)\n",
        "    blob.upload_from_filename(imgfile)\n",
        "    # print(f'File {imgfile} uploaded to {relative_path}.')\n",
        "#  print(studentId)\n",
        "\n",
        " encodeList=[]\n",
        " def encodingImg(imgList): # Changed function parameter to imgList to reflect that it's processing a list\n",
        "\n",
        "    for img in imgList: # Iterate over each image in the list\n",
        "        img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "        encode=face_recognition.face_encodings(img) # Use img instead of i\n",
        "        encodeList.append(encode)\n",
        "    return encodeList\n",
        "\n",
        "#  print('encoding Started...')\n",
        " encodes=encodingImg(modelist) # Pass the list of images\n",
        " unknownId=[encodes[0],studentId]\n",
        "#  print('encoding Complete...')\n",
        " # print(unknownId)\n",
        "\n",
        " file =open('./sample_data/encoding.p','wb')\n",
        " pickle.dump(unknownId,file)\n",
        " file.close()\n",
        "#  print('File Saved')\n",
        "\n",
        " file = open('./sample_data/encoding.p','rb')\n",
        " encodeListknownId=pickle.load(file)\n",
        " file.close()\n",
        " un , std = encodeListknownId\n",
        "#  print(std)\n",
        "\n",
        "\n",
        "\n",
        " # print(modelist)\n",
        " filepath2=cv2.imread(os.path.join('/content/unknown','photo.jpg'))\n",
        "\n",
        " def encodingImg2(img): # Changed function parameter to imgList to reflect that it's processing a list\n",
        "        img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "        encode=face_recognition.face_encodings(img) # Use img instead of i\n",
        "        return encode\n",
        "\n",
        " encodehello = encodingImg2(filepath2)\n",
        " i=0\n",
        " Matches=[]\n",
        " FaceDistance=[]\n",
        "\n",
        " try:\n",
        "  while i<len(encodes):\n",
        "    for items in encodes[i]:\n",
        "      match1=face_recognition.compare_faces(items,encodehello)\n",
        "      facedis=face_recognition.face_distance(items,encodehello)\n",
        "      Matches.append(match1[0])\n",
        "      FaceDistance.append(facedis[0])\n",
        "    i=i+1\n",
        " except Exception as err:\n",
        "     print(\"Retake The Photo Please\")\n",
        "     Retake()\n",
        "     return\n",
        "#  print(Matches)\n",
        "#  print(FaceDistance)\n",
        " if True in Matches:\n",
        "   index=np.argmin(FaceDistance)\n",
        "   ID=studentId[index]\n",
        "   IDref=db.reference(f'students/{ID}')\n",
        "  #  print(IDref.get())\n",
        "   studentInfo=IDref.get()\n",
        "   datetimeObject = datetime.strptime(studentInfo['last_attendance_time'],\"%Y-%m-%d %H:%M:%S\")\n",
        "   secondsElapsed = (datetime.now() - datetimeObject).total_seconds()\n",
        "  #  print(secondsElapsed)\n",
        "   if secondsElapsed > 30:\n",
        "     studentInfo['Total_attendance'] += 1\n",
        "     IDref.child('Total_attendance').set(studentInfo['Total_attendance'])\n",
        "     IDref.child('last_attendance_time').set(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
        "     delay=2\n",
        "     checked=cv2.imread('/content/drive/MyDrive/display/checked.jpg')\n",
        "     cv2_imshow(checked)\n",
        "     time.sleep(delay)\n",
        "     clear_output()\n",
        "\n",
        "\n",
        "     Downblob=bucket.get_blob(f'{ID}.jpg')\n",
        "     array=np.frombuffer(Downblob.download_as_string(),np.uint8)\n",
        "     image1=cv2.imdecode(array,cv2.IMREAD_COLOR)\n",
        "     # Load the images\n",
        "     img2 = cv2.imread('/content/drive/MyDrive/display/info.jpg')\n",
        "     text = f\"{studentInfo['name']}\"\n",
        "\n",
        "     # Resize the images to the same size (if needed)\n",
        "     img1 = cv2.resize(image1, (300, 400))\n",
        "     img2 = cv2.resize(img2, (300, 400))\n",
        "     # Define the position, font, scale, color, and thickness of the text\n",
        "     position = (75, 105)  # (x, y) coordinates for the bottom-left corner of the text\n",
        "     font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "     font_scale = 0.7\n",
        "     color = (255, 255, 255)  # BGR (Blue, Green, Red)\n",
        "     thickness = 2\n",
        "     # Add text to the image\n",
        "     cv2.putText(img2, text, position, font, font_scale, color, thickness)\n",
        "\n",
        "     text = f\"ETS{ID}/13\"\n",
        "     position = (45, 170)  # (x, y) coordinates for the bottom-left corner of the text\n",
        "     font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "     font_scale = 0.7\n",
        "     color = (255, 255, 255)  # BGR (Blue, Green, Red)\n",
        "     thickness = 2\n",
        "     # Add text to the image\n",
        "     cv2.putText(img2, text, position, font, font_scale, color, thickness)\n",
        "\n",
        "     text = f\"{studentInfo['department']}\"\n",
        "     position = (137, 235)  # (x, y) coordinates for the bottom-left corner of the text\n",
        "     font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "     font_scale = 0.7\n",
        "     color = (255, 255, 255)  # BGR (Blue, Green, Red)\n",
        "     thickness = 2\n",
        "     # Add text to the image\n",
        "     cv2.putText(img2, text, position, font, font_scale, color, thickness)\n",
        "\n",
        "     text = f\"{studentInfo['course']}\"\n",
        "     position = (88, 302)  # (x, y) coordinates for the bottom-left corner of the text\n",
        "     font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "     font_scale = 0.7\n",
        "     color = (255, 255, 255)  # BGR (Blue, Green, Red)\n",
        "     thickness = 2\n",
        "     # Add text to the image\n",
        "     cv2.putText(img2, text, position, font, font_scale, color, thickness)\n",
        "\n",
        "     text = f\"{studentInfo['Total_attendance']}\"\n",
        "     position = (185, 360)  # (x, y) coordinates for the bottom-left corner of the text\n",
        "     font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "     font_scale = 0.7\n",
        "     color = (255, 255, 255)  # BGR (Blue, Green, Red)\n",
        "     thickness = 2\n",
        "     # Add text to the image\n",
        "     cv2.putText(img2, text, position, font, font_scale, color, thickness)\n",
        "\n",
        "\n",
        "\n",
        "     # Concatenate the images horizontally\n",
        "     img_combined = cv2.hconcat([img1, img2])\n",
        "     # Display the combined image\n",
        "     cv2_imshow(img_combined)\n",
        "     # Wait for the user to close the window\n",
        "     # cv2.waitKey(0)\n",
        "     # cv2.destroyAllWindows()\n",
        "     delay=10\n",
        "     time.sleep(delay)\n",
        "     clear_output()\n",
        "     Retake()\n",
        "   else:\n",
        "      al_img=cv2.imread('/content/drive/MyDrive/display/already.jpg')\n",
        "      cv2_imshow(al_img)\n",
        "      delay=5\n",
        "      time.sleep(delay)\n",
        "      clear_output()\n",
        "      Retake()\n",
        " else:\n",
        "    un_img=cv2.imread('/content/drive/MyDrive/display/unregistered.jpg')\n",
        "    cv2_imshow(un_img)\n",
        "    delay=5\n",
        "    time.sleep(delay)\n",
        "    clear_output()\n",
        "    Retake()\n",
        "Retake()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "VrlPnj3vhY-D",
        "outputId": "6c59fdc5-589f-493f-e041-1536b9a6cd6f",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# import firebase_admin\n",
        "# from firebase_admin import credentials\n",
        "# from firebase_admin import db\n",
        "\n",
        "\n",
        "\n",
        "# # cred = credentials.Certificate(\"/content/drive/MyDrive/serviceAccountKey.json\")\n",
        "# # firebase_admin.initialize_app(cred,{\n",
        "# #     \"databaseURL\":\"https://facerecondb-default-rtdb.firebaseio.com/\"\n",
        "# # })\n",
        "\n",
        "# ref=db.reference('students')\n",
        "\n",
        "\n",
        "# data= {\n",
        "# \"1316\":{\n",
        "#     \"name\":\"Yihun Melkam\",\n",
        "#     \"major\":\"Computer\",\n",
        "#     \"starting_year\":2021,\n",
        "#     \"Total_attendace\":9,\n",
        "#     \"Year\":4,\n",
        "#     \"last_attendance_time\":\"2024-02-12 00:00:00\"\n",
        "# },\n",
        "# \"0273\":{\n",
        "#     \"name\":\"Biniyam Gedefaw\",\n",
        "#     \"major\":\"Computer\",\n",
        "#     \"starting_year\":2021,\n",
        "#     \"Total_attendace\":8,\n",
        "#     \"Year\":4,\n",
        "#     \"last_attendance_time\":\"2024-02-12 00:00:00\"\n",
        "# }\n",
        "# }\n",
        "\n",
        "\n",
        "# for key,value in data.items():\n",
        "#     ref.child(key).set(value)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cEv4ynv9DAk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mjv1Aehz4bXL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}