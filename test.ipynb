{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Biniyamgd/IDP/blob/main/test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvozMDLVaGsl",
        "outputId": "c8051bcb-e755-44bf-fd41-7ec1adabc5e2",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dlib in /usr/local/lib/python3.10/dist-packages (19.24.4)\n",
            "Collecting face_recognition\n",
            "  Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting face-recognition-models>=0.3.0 (from face_recognition)\n",
            "  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.1/100.1 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (8.1.7)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (19.24.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from face_recognition) (1.25.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from face_recognition) (9.4.0)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566170 sha256=29d28da42c236d46e21cd766e4fb0b7daa707c0a47d0df6e0a54b694130149a4\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/eb/cf/e9eced74122b679557f597bb7c8e4c739cfcac526db1fd523d\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face_recognition\n",
            "Successfully installed face-recognition-models-0.3.0 face_recognition-1.3.0\n",
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<firebase_admin.App at 0x7ecbc8623580>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!pip install dlib\n",
        "!pip install face_recognition\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import firebase_admin\n",
        "from firebase_admin import credentials\n",
        "import os\n",
        "\n",
        "if not os.path.exists('./unknown'):\n",
        "   os.mkdir('./unknown')\n",
        "\n",
        "\n",
        "cred = credentials.Certificate(\"/content/drive/MyDrive/serviceAccountKey.json\")\n",
        "firebase_admin.initialize_app(cred,{\n",
        "    \"databaseURL\":\"https://facerecondb-default-rtdb.firebaseio.com/\",\n",
        "    \"storageBucket\":\"facerecondb.appspot.com\"\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='./unknown/photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "\n",
        "\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      capture.style.width = '160px';\n",
        "      capture.style.height = '30px';\n",
        "      capture.style.border=\"none\";\n",
        "      capture.style.color=\"black\";\n",
        "      capture.style.borderRadius=\"7px\";\n",
        "      capture.style.backgroundColor=\"rgb(100,165,145)\";\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename"
      ],
      "metadata": {
        "id": "OaEtSKythY99"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, clear_output\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "import face_recognition\n",
        "import numpy as np\n",
        "import firebase_admin\n",
        "from firebase_admin import storage\n",
        "from firebase_admin import db\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "def Retake():\n",
        " try:\n",
        "   filename = take_photo()\n",
        " except Exception as err:\n",
        "   print(str(err))\n",
        "\n",
        "\n",
        "\n",
        " filepath='./drive/MyDrive/students'\n",
        " folder=os.listdir(filepath)\n",
        " modelist=[]\n",
        " studentId=[]\n",
        "\n",
        "\n",
        " for Path in folder:\n",
        "  if os.path.isfile(os.path.join(filepath, Path)) and Path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "    modelist.append(cv2.imread(os.path.join(filepath,Path)))\n",
        "    studentId.append(os.path.splitext(Path)[0])\n",
        "    imgfile=os.path.join(filepath,Path)\n",
        "    relative_path = os.path.relpath(imgfile, filepath)\n",
        "    bucket=storage.bucket()\n",
        "    blob = bucket.blob(relative_path)\n",
        "    blob.upload_from_filename(imgfile)\n",
        "\n",
        "\n",
        " encodeList=[]\n",
        " def encodingImg(imgList):\n",
        "    for img in imgList:\n",
        "        img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "        encode=face_recognition.face_encodings(img)\n",
        "        encodeList.append(encode)\n",
        "    return encodeList\n",
        "\n",
        "\n",
        " encodes=encodingImg(modelist)\n",
        "\n",
        " filepath2=cv2.imread(os.path.join('/content/unknown','photo.jpg'))\n",
        "\n",
        " def encodingImg2(img):\n",
        "        img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "        encode=face_recognition.face_encodings(img)\n",
        "        return encode\n",
        "\n",
        " encodehello = encodingImg2(filepath2)\n",
        " i=0\n",
        " Matches=[]\n",
        " FaceDistance=[]\n",
        "\n",
        " try:\n",
        "  while i<len(encodes):\n",
        "    for items in encodes[i]:\n",
        "      match1=face_recognition.compare_faces(items,encodehello)\n",
        "      facedis=face_recognition.face_distance(items,encodehello)\n",
        "      Matches.append(match1[0])\n",
        "      FaceDistance.append(facedis[0])\n",
        "    i=i+1\n",
        " except Exception as err:\n",
        "     print(\"Retake The Photo Please\")\n",
        "     Retake()\n",
        "     return\n",
        " if True in Matches:\n",
        "   checked=cv2.imread('/content/drive/MyDrive/display/checked.jpg')\n",
        "   cv2_imshow(checked)\n",
        "   index=np.argmin(FaceDistance)\n",
        "   ID=studentId[index]\n",
        "   IDref=db.reference(f'students/{ID}')\n",
        "   studentInfo=IDref.get()\n",
        "   datetimeObject = datetime.strptime(studentInfo['last_attendance_time'],\"%Y-%m-%d %H:%M:%S\")\n",
        "   secondsElapsed = (datetime.now() - datetimeObject).total_seconds()\n",
        "   if secondsElapsed > 60:\n",
        "     studentInfo['Total_attendance'] += 1\n",
        "     IDref.child('Total_attendance').set(studentInfo['Total_attendance'])\n",
        "     IDref.child('last_attendance_time').set(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
        "     clear_output()\n",
        "\n",
        "\n",
        "     Downblob=bucket.get_blob(f'{ID}.jpg')\n",
        "     array=np.frombuffer(Downblob.download_as_string(),np.uint8)\n",
        "     image1=cv2.imdecode(array,cv2.IMREAD_COLOR)\n",
        "\n",
        "     img2 = cv2.imread('/content/drive/MyDrive/display/info.jpg')\n",
        "     text = f\"{studentInfo['name']}\"\n",
        "\n",
        "     img1 = cv2.resize(image1, (300, 400))\n",
        "     img2 = cv2.resize(img2, (300, 400))\n",
        "\n",
        "     position = (75, 105)\n",
        "     font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "     font_scale = 0.7\n",
        "     color = (255, 255, 255)\n",
        "     thickness = 2\n",
        "     cv2.putText(img2, text, position, font, font_scale, color, thickness)\n",
        "\n",
        "     text = f\"ETS{ID}/13\"\n",
        "     position = (45, 170)\n",
        "     font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "     font_scale = 0.7\n",
        "     color = (255, 255, 255)\n",
        "     thickness = 2\n",
        "     cv2.putText(img2, text, position, font, font_scale, color, thickness)\n",
        "\n",
        "     text = f\"{studentInfo['department']}\"\n",
        "     position = (137, 235)\n",
        "     font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "     font_scale = 0.7\n",
        "     color = (255, 255, 255)\n",
        "     thickness = 2\n",
        "\n",
        "     cv2.putText(img2, text, position, font, font_scale, color, thickness)\n",
        "\n",
        "     text = f\"{studentInfo['course']}\"\n",
        "     position = (88, 302)\n",
        "     font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "     font_scale = 0.7\n",
        "     color = (255, 255, 255)\n",
        "     thickness = 2\n",
        "     cv2.putText(img2, text, position, font, font_scale, color, thickness)\n",
        "\n",
        "     text = f\"{studentInfo['Total_attendance']}\"\n",
        "     position = (185, 360)\n",
        "     font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "     font_scale = 0.7\n",
        "     color = (255, 255, 255)\n",
        "     thickness = 2\n",
        "     cv2.putText(img2, text, position, font, font_scale, color, thickness)\n",
        "\n",
        "\n",
        "     img_combined = cv2.hconcat([img1, img2])\n",
        "     cv2_imshow(img_combined)\n",
        "     delay=10\n",
        "     time.sleep(delay)\n",
        "     clear_output()\n",
        "     Retake()\n",
        "   else:\n",
        "      clear_output()\n",
        "      al_img=cv2.imread('/content/drive/MyDrive/display/already.jpg')\n",
        "      cv2_imshow(al_img)\n",
        "      delay=5\n",
        "      time.sleep(delay)\n",
        "      clear_output()\n",
        "      Retake()\n",
        " else:\n",
        "    un_img=cv2.imread('/content/drive/MyDrive/display/unregistered.jpg')\n",
        "    cv2_imshow(un_img)\n",
        "    delay=5\n",
        "    time.sleep(delay)\n",
        "    clear_output()\n",
        "    Retake()\n",
        "Retake()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "VrlPnj3vhY-D",
        "outputId": "e388a81d-68e9-4a56-ee96-2e0807d6adc7",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      \n",
              "      \n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      \n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      capture.style.width = '160px';\n",
              "      capture.style.height = '30px';\n",
              "      capture.style.border=\"none\";\n",
              "      capture.style.color=\"black\";\n",
              "      capture.style.borderRadius=\"7px\";\n",
              "      capture.style.backgroundColor=\"rgb(100,165,145)\";\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    }
  ]
}